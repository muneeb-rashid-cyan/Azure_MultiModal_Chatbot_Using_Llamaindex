# Azure Multimodal Chatbot Using Llamaindex

This project demonstrates an end-to-end solution for a multimodal chatbot using various Azure services and Langchain. The chatbot supports text and voice input, utilizes a vector database for efficient search, leverages Azure OpenAI models for generating responses, and incorporates Azure Vision for image-based queries.

## Features

- Multimodal input: text, voice, and image.
- Integration with Azure AI Search Vector DB for efficient information retrieval.
- Utilizes Azure OpenAI models for natural language understanding and generation.
- Supports authentication via Azure Active Directory.
- Converts text to speech using Azure Text to Speech services.
- Processes images using Azure Vision models.
- User-friendly interface with Streamlit.

## Getting Started

Follow these instructions to set up and run the project locally.

### Prerequisites

- Python 3.7 or higher
- Pip (Python package installer)
- Azure subscription
- Azure Active Directory setup
- Azure OpenAI, Text to Speech, and Vision service keys
- Azure AI Search Vector DB setup
